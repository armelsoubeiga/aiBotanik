#!/usr/bin/env python3
import requests
import json

def test_frontend_integration():
    """Test l'intÃ©gration complÃ¨te frontend/backend pour l'affichage des sections structurÃ©es"""
    
    print("ğŸ§ª Test d'intÃ©gration frontend/backend - Sections structurÃ©es")
    print("=" * 60)
    
    # Test 1: VÃ©rifier la configuration actuelle
    config_response = requests.get('http://localhost:8000/admin/config/llm')
    config = config_response.json()
    print(f"âœ… Backend actuel: {config['llm_backend']}")
    
    # Test 2: Tester une recommandation complÃ¨te
    test_cases = [
        {
            "name": "Test paludisme (OpenAI)",
            "request": {"plant_name": "Artemisia", "symptoms": "fiÃ¨vre et frissons du paludisme", "user_profile": "adulte"},
            "backend": "openai"
        },
        {
            "name": "Test diarrhÃ©e (Hugging Face fallback)",
            "request": {"plant_name": "Aloe", "symptoms": "diarrhÃ©e", "user_profile": "adulte"},
            "backend": "huggingface"
        }
    ]
    
    for test_case in test_cases:
        print(f"\nğŸ“‹ {test_case['name']}")
        print("-" * 40)
        
        # Changer de backend si nÃ©cessaire
        current_config = requests.get('http://localhost:8000/admin/config/llm').json()
        if current_config['llm_backend'] != test_case['backend']:
            change_response = requests.put('http://localhost:8000/admin/config/llm', 
                                         json={'llm_backend': test_case['backend']})
            print(f"Backend changÃ© pour: {test_case['backend']}")
        
        # Faire la recommandation
        response = requests.post('http://localhost:8000/recommend', json=test_case['request'])
        
        if response.status_code == 200:
            data = response.json()
            
            # VÃ©rifier les champs structurÃ©s
            structured_fields = [
                'diagnostic', 'symptomes', 'presentation', 'mode_action', 
                'traitement_info', 'precautions_info', 'composants_info', 'resume_traitement'
            ]
            
            print("ğŸ“Š Statut des champs structurÃ©s:")
            all_present = True
            total_chars = 0
            
            for field in structured_fields:
                value = data.get(field, "")
                if value and len(value.strip()) > 0:
                    char_count = len(value)
                    total_chars += char_count
                    print(f"  âœ… {field}: {char_count} caractÃ¨res")
                else:
                    all_present = False
                    print(f"  âŒ {field}: MANQUANT ou vide")
            
            if all_present:
                print(f"ğŸ‰ Tous les champs structurÃ©s sont prÃ©sents! ({total_chars} caractÃ¨res au total)")
            else:
                print("âš ï¸  Certains champs structurÃ©s sont manquants")
            
            # Afficher un Ã©chantillon de contenu
            if data.get('diagnostic'):
                print(f"ğŸ“ Ã‰chantillon diagnostic: \"{data['diagnostic'][:100]}...\"")
            
            # VÃ©rifier la cohÃ©rence frontend
            print("ğŸ–¥ï¸  PrÃªt pour l'affichage frontend:")
            print(f"  - Plante: {data.get('plant', 'N/A')}")
            print(f"  - Image: {'âœ…' if data.get('image_url') else 'âŒ'}")
            print(f"  - Sections individuelles: {'âœ…' if all_present else 'âŒ'}")
            print(f"  - Explication complÃ¨te: {'âœ…' if data.get('explanation') else 'âŒ'}")
            
        else:
            print(f"âŒ Erreur API: {response.status_code} - {response.text}")
    
    # Remettre OpenAI par dÃ©faut
    requests.put('http://localhost:8000/admin/config/llm', json={'llm_backend': 'openai'})
    print(f"\nğŸ”„ Backend remis sur OpenAI")
    
    print("\n" + "=" * 60)
    print("âœ… Test d'intÃ©gration terminÃ©!")
    print("ğŸŒ Ouvrez http://localhost:3000 pour tester l'interface utilisateur")

if __name__ == "__main__":
    test_frontend_integration()
